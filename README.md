 

---

![Glue Project](https://github.com/user-attachments/assets/d69274b3-b8ec-41c2-bf6c-899fd5491c5b)

### **ğŸš€ Incremental Data Load Using AWS Glue**  

ğŸ“Œ **Tech Stack**:  
- **Language**: Python  
- **Storage**: S3 Bucket  
- **ETL Service**: AWS Glue  

---

### **ğŸ”„ Data Flow Overview**  
1ï¸âƒ£ **Upload Daily Input File** â†’ ğŸ“‚ **S3 Bucket (telecom-data-glue-analysis)**  
2ï¸âƒ£ **Metadata Extraction** â†’ ğŸ” **AWS Glue Crawler**  
3ï¸âƒ£ **Schema Storage** â†’ ğŸ“‹ **AWS Glue Data Catalog**  
4ï¸âƒ£ **Data Processing** â†’ ğŸ”¥ **AWS Glue Job (PySpark)**  
5ï¸âƒ£ **Avoid Duplication** â†’ ğŸ“Œ **Glue Job Bookmarking**  
6ï¸âƒ£ **Execute & Validate** â†’ âœ… **Print Records & Count in Logs**  

---

### **ğŸ›  Steps to Implement**  

ğŸ”¹ **Step 1**: ğŸ“¥ **Create S3 Bucket**  
ğŸ“Œ Name: `telecom-data-glue-analysis`  

ğŸ”¹ **Step 2**: ğŸ› **Create Glue Database**  
ğŸ“Œ Name: `telecom-data` (Under AWS Glue â†’ Databases)  

ğŸ”¹ **Step 3**: ğŸ” **Configure Glue Crawler**  
ğŸ“Œ Name: `telecom-data-crawler`  
ğŸ“Œ Set source as S3 â†’ Run Crawler â†’ Creates Metadata Table  

ğŸ”¹ **Step 4**: ğŸ“ **Write AWS Glue Script**  
ğŸ“Œ Read Data Using **Glue Catalog & PySpark**  
ğŸ“Œ Print **Records + Count in Output Logs**  

ğŸ”¹ **Step 5**: ğŸ”§ **Use Glue Visual ETL (Script Editor)**  
ğŸ“Œ Choose **Spark Option**  
ğŸ“Œ Write `incremental_data_in_glue.py`  

ğŸ”¹ **Step 6**: âš™ï¸ **Configure Glue Job**  
ğŸ“Œ **Add Job Parameter**: `--JOB_NAME = glue-data-test`  
ğŸ“Œ **Enable Job Bookmarking** to avoid reprocessing  

ğŸ”¹ **Step 7**: â–¶ï¸ **Run Glue Job & Verify Logs**  
ğŸ“Œ Check **Output Logs** for **Processed Data & Count**  

---

ğŸ¯ **Outcome**:  
ğŸš€ **Automated Incremental Data Load** with **No Duplicate Processing** in AWS Glue!  
